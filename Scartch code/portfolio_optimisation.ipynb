{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cp\n",
    "from sklearn.covariance import LedoitWolf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd61f4",
   "metadata": {},
   "source": [
    "### Forex & Interest rate Data Processing and Excess Returns Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a52e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_raw = pd.read_csv(\"FX_rates.csv\")\n",
    "\n",
    "currency_row = fx_raw.iloc[0, 1:].values\n",
    "fx = fx_raw.iloc[1:].copy()\n",
    "fx[\"Time Period\"] = pd.PeriodIndex(fx[\"Time Period\"], freq=\"M\")\n",
    "fx = fx.set_index(\"Time Period\")\n",
    "fx = fx.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "fx_adj = fx.copy()\n",
    "for col, curr in zip(fx.columns, currency_row):\n",
    "    if curr != \"USD\":\n",
    "        fx_adj[col] = 1.0 / fx_adj[col]\n",
    "\n",
    "delta_s = np.log(fx_adj).diff().dropna(how=\"all\").round(6)\n",
    "\n",
    "\n",
    "rf_raw = pd.read_csv(\"Risk Free Rates.csv\")\n",
    "currency_to_country = {\n",
    "    \"USD\": \"USD\",\n",
    "    \"AUD\": \"AUSTRALIA\", \"CAD\": \"CANADA\", \"EUR\": \"EURO AREA\",\n",
    "    \"BRL\": \"BRAZIL\", \"CHF\": \"SWITZERLAND\", \"DKK\": \"DENMARK\",\n",
    "    \"GBP\": \"UNITED KINGDOM\", \"JPY\": \"JAPAN\", \"KRW\": \"KOREA\",\n",
    "    \"ZAR\": \"SOUTH AFRICA\", \"TWD\": \"TAIWAN\", \"SGD\": \"SINGAPORE\",\n",
    "    \"NZD\": \"NEW ZEALAND\", \"MXN\": \"MEXICO\", \"NOK\": \"NORWAY\",\n",
    "    \"INR\": \"INDIA\", \"CNY\": \"CHINA\", \"SEK\": \"SWEDEN\",\"HUF\":\"HUNGARY\",\n",
    "    \"CZK\":\"CZECHIA\",\"TRY\":\"TURKEY\"\n",
    "}\n",
    "rf = rf_raw.rename(columns=currency_to_country)\n",
    "\n",
    "fx_countries = delta_s.columns\n",
    "for country in fx_countries:\n",
    "    if country not in rf.columns:\n",
    "        rf[country] = np.nan\n",
    "\n",
    "rf[\"Time Period\"] = pd.to_datetime(rf[\"Time Period\"], format=\"%Y%m%d\", errors='coerce')\n",
    "rf = rf.set_index(\"Time Period\")\n",
    "rf = rf.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "rf_monthly = rf.resample('ME').mean().round(6)\n",
    "rf_monthly.index = rf_monthly.index.to_period(\"M\")\n",
    "\n",
    "\n",
    "common_index = delta_s.index.intersection(rf_monthly.index)\n",
    "delta_s = delta_s.loc[common_index]\n",
    "rf_monthly = rf_monthly.loc[common_index]\n",
    "\n",
    "usd_rf = rf_monthly[\"USD\"]\n",
    "\n",
    "excess_returns = pd.DataFrame(index=common_index, columns=delta_s.columns, dtype=float)\n",
    "\n",
    "for col in delta_s.columns:\n",
    "    if col not in rf_monthly.columns:\n",
    "        continue\n",
    "\n",
    "    mask = delta_s[col].notna() & rf_monthly[col].notna() & usd_rf.notna()\n",
    "    excess_returns.loc[mask, col] = rf_monthly.loc[mask, col] - usd_rf.loc[mask] - delta_s.loc[mask, col]\n",
    "\n",
    "excess_returns.round(6).drop([\"INDIA\", \"CHINA\", \"KOREA\"], axis=1).to_csv(\"FX_excess_returns.csv\", na_rep=\"NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53fc320",
   "metadata": {},
   "source": [
    "## Full-Sample Markowitz Tangency Portfolio (With efficient frontier + cumulative return plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9148d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = excess_returns.mean().values          \n",
    "cov = excess_returns.cov().values          \n",
    "\n",
    "# Tangency Portfolio\n",
    "def markowitz_tangency(mu, cov):\n",
    "    inv_cov = np.linalg.inv(cov)\n",
    "    ones = np.ones(len(mu))\n",
    "\n",
    "    w = inv_cov @ mu\n",
    "    w = w / (ones @ w)\n",
    "    return w\n",
    "\n",
    "w_full = markowitz_tangency(mu, cov)\n",
    "\n",
    "print(\"Full-Sample Tangency Weights (Shorting Allowed):\")\n",
    "print(w_full)\n",
    "\n",
    "# Efficient Frontier\n",
    "def efficient_frontier(mu, cov, points=50):\n",
    "    mu = mu.reshape(-1, 1)\n",
    "    ones = np.ones((len(mu), 1))\n",
    "    inv_cov = np.linalg.inv(cov)\n",
    "\n",
    "    A = ones.T @ inv_cov @ ones   \n",
    "    B = ones.T @ inv_cov @ mu       \n",
    "    C = mu.T @ inv_cov @ mu         \n",
    "    D = A*C - B**2                 \n",
    "\n",
    "    target_returns = np.linspace(mu.min(), mu.max(), points)\n",
    "\n",
    "    vols = []\n",
    "    rets = []\n",
    "\n",
    "    for r in target_returns:\n",
    "        r = float(r)\n",
    "        w = ((C - B*r)/D) * (inv_cov @ ones) + ((A*r - B)/D) * (inv_cov @ mu)\n",
    "        w = w.flatten()\n",
    "        vol = np.sqrt(w.T @ cov @ w)\n",
    "\n",
    "        vols.append(vol)\n",
    "        rets.append(r)\n",
    "\n",
    "    return vols, rets\n",
    "\n",
    "sigma, ret_list = efficient_frontier(mu, cov)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(sigma, ret_list)\n",
    "plt.title(\"Efficient Frontier — Short-Sale Allowed\")\n",
    "plt.xlabel(\"Volatility\")\n",
    "plt.ylabel(\"Return\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Cumulative Return of Tangency Portfolio\n",
    "full_sample_portfolio_returns = excess_returns.values @ w_full\n",
    "cum = (1 + full_sample_portfolio_returns).cumprod()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(cum)\n",
    "plt.title(\"Cumulative Return — Tangency Port (Shorting Allowed)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11573a72",
   "metadata": {},
   "source": [
    "## Rolling Sample Markowitz Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff1143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tangency portfolio (short selling allowed)\n",
    "\n",
    "def markowitz_tangency(mu, cov):\n",
    "    mu = np.asarray(mu).reshape(-1)\n",
    "    cov = np.asarray(cov)\n",
    "    inv_cov = np.linalg.inv(cov)\n",
    "\n",
    "    ones = np.ones(len(mu))\n",
    "\n",
    "    w = inv_cov @ mu\n",
    "    w = w / (ones @ w)   # budget constraint 1'w = 1\n",
    "\n",
    "    return w\n",
    "\n",
    "# Rolling Out-of-Sample Evaluation\n",
    "\n",
    "window = 60\n",
    "rets = excess_returns.copy()\n",
    "oos = []\n",
    "\n",
    "for t in range(window, len(rets) - 1):\n",
    "\n",
    "    sample = rets.iloc[t-window:t]\n",
    "\n",
    "    # convert to numpy\n",
    "    mu_t = sample.mean().values\n",
    "    cov_t = sample.cov().values\n",
    "\n",
    "    w_t = markowitz_tangency(mu_t, cov_t)\n",
    "    r_next = np.dot(rets.iloc[t+1].values, w_t)\n",
    "    oos.append(r_next)\n",
    "\n",
    "rolling_markowitz = pd.Series(oos, index=rets.index[window+1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccc5c1c",
   "metadata": {},
   "source": [
    "## Naive 1/N Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a04534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of assets\n",
    "N = excess_returns.shape[1]\n",
    "\n",
    "# equal weights, short selling allowed\n",
    "# (weights sum to 1, no sign restrictions needed)\n",
    "w_equal = np.ones(N) / N\n",
    "\n",
    "# out-of-sample returns aligned after 60-month window\n",
    "naive_returns = (excess_returns @ w_equal).iloc[60:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778feec5",
   "metadata": {},
   "source": [
    "## Markowitz based on Shrinkage Estimaator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fb70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 60\n",
    "rets = excess_returns.copy()\n",
    "\n",
    "oos_lw = []\n",
    "\n",
    "for t in range(window, len(rets)-1):\n",
    "\n",
    "    sample = rets.iloc[t-window:t]\n",
    "    mu_t = sample.mean().values\n",
    "\n",
    "    # Ledoit–Wolf shrinkage covariance\n",
    "    lw = LedoitWolf().fit(sample.values)\n",
    "    cov_t = lw.covariance_\n",
    "\n",
    "    # Tangency Portfolio\n",
    "    inv_cov = np.linalg.inv(cov_t)\n",
    "    w = inv_cov @ mu_t\n",
    "\n",
    "    # budget constraint: 1'w = 1 (no sign restrictions)\n",
    "    w = w / (np.ones(len(mu_t)) @ w)\n",
    "\n",
    "    r_next = np.dot(rets.iloc[t+1].values, w)\n",
    "    oos_lw.append(r_next)\n",
    "\n",
    "lw_returns = pd.Series(oos_lw, index=rets.index[window+1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc2dbe7",
   "metadata": {},
   "source": [
    "## Constrained Markowitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8ba285",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tangency portfolio via mean-variance optimization\n",
    "# Short-selling allowed, only sum(w)=1\n",
    "\n",
    "def cvxpy_tangency(mu, cov, gamma=1e-6):\n",
    "    n = len(mu)\n",
    "    w = cp.Variable(n)\n",
    "\n",
    "    objective = cp.Maximize(mu @ w - gamma * cp.quad_form(w, cov))\n",
    "    constraints = [cp.sum(w) == 1]   # only sum constraint, short-selling allowed\n",
    "\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "\n",
    "    try:\n",
    "        prob.solve(solver=cp.ECOS)\n",
    "    except:\n",
    "        prob.solve(solver=cp.SCS, verbose=False)\n",
    "\n",
    "    w_val = w.value\n",
    "\n",
    "    if w_val is None:\n",
    "        w_val = np.ones(n) / n\n",
    "\n",
    "    # normalize to ensure sum = 1\n",
    "    return w_val / np.sum(w_val)\n",
    "\n",
    "\n",
    "# Rolling out-of-sample\n",
    "\n",
    "window = 60\n",
    "rets = excess_returns.copy()\n",
    "oos_shrink = []\n",
    "\n",
    "for t in range(window, len(rets)-1):\n",
    "    sample = rets.iloc[t-window:t]\n",
    "\n",
    "    mu_t = sample.mean().values\n",
    "    cov_t = sample.cov().values\n",
    "\n",
    "    w_t = cvxpy_tangency(mu_t, cov_t)\n",
    "    r_next = np.dot(rets.iloc[t+1].values, w_t)\n",
    "    oos_shrink.append(r_next)\n",
    "\n",
    "cvx_returns = pd.Series(oos_shrink, index=rets.index[window+1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e73b16",
   "metadata": {},
   "source": [
    "## Resampling based Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5de336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_weights(sample, B=500):\n",
    "    \"\"\"\n",
    "    Compute resampled tangency portfolio weights (Michaud)\n",
    "    Short-selling allowed.\n",
    "    \n",
    "    sample : pd.DataFrame : window of returns\n",
    "    B : int : number of bootstrap samples\n",
    "    \"\"\"\n",
    "    N = sample.shape[1]\n",
    "    weights = []\n",
    "\n",
    "    for _ in range(B):\n",
    "        # bootstrap indices\n",
    "        idx = np.random.choice(len(sample), size=len(sample), replace=True)\n",
    "        boot = sample.iloc[idx]\n",
    "\n",
    "        # sample mean and cov\n",
    "        mu_b = boot.mean().values\n",
    "        cov_b = boot.cov().values\n",
    "\n",
    "        # ensure covariance is invertible\n",
    "        try:\n",
    "            w_b = np.linalg.inv(cov_b) @ mu_b\n",
    "            # normalize weights to sum to 1\n",
    "            w_b = w_b / np.sum(w_b)\n",
    "            weights.append(w_b)\n",
    "        except np.linalg.LinAlgError:\n",
    "            continue\n",
    "\n",
    "    return np.mean(weights, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# Rolling Out-of-Sample Portfolio\n",
    "\n",
    "window = 60\n",
    "rets = excess_returns.copy()\n",
    "oos = []\n",
    "\n",
    "for t in range(window, len(rets)-1):\n",
    "    sample = rets.iloc[t-window:t]\n",
    "\n",
    "    w_bar = bootstrap_weights(sample, B=300)\n",
    "\n",
    "    r_next = np.dot(rets.iloc[t+1].values, w_bar)\n",
    "    oos.append(r_next)\n",
    "\n",
    "boot_returns = pd.Series(oos, index=rets.index[window+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd1397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this before plotting\n",
    "def ensure_ts(s):\n",
    "    if s is None:\n",
    "        return None\n",
    "    s = s.dropna()\n",
    "    if s.empty:\n",
    "        return None\n",
    "    if isinstance(s.index, pd.PeriodIndex):\n",
    "        s = s.copy(); s.index = s.index.to_timestamp()\n",
    "    return s\n",
    "\n",
    "for name in ('excess_returns','w_full','naive_returns'):\n",
    "    print(name, 'exists:', name in globals())\n",
    "\n",
    "naive_plot = ensure_ts(globals().get('naive_returns'))\n",
    "markowitz_plot = ensure_ts(globals().get('rolling_markowitz'))\n",
    "print('naive_plot ok?', naive_plot is not None)\n",
    "\n",
    "# Diagnostics\n",
    "print(\"naive_returns head:\\n\", naive_returns.head())\n",
    "print(\"non-null count:\", naive_returns.dropna().shape[0])\n",
    "print(\"index type:\", type(naive_returns.index))\n",
    "print(\"is PeriodIndex:\", isinstance(naive_returns.index, pd.PeriodIndex))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae616aa",
   "metadata": {},
   "source": [
    "## Rolling Sharpe Ratio Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef80d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_sharpe(return_series, window=36):\n",
    "    return (return_series.rolling(window).mean() /\n",
    "            return_series.rolling(window).std())\n",
    "\n",
    "def _plot_sharpe_series(series, label, window=36):\n",
    "    s = rolling_sharpe(series, window).dropna()\n",
    "    # PeriodIndex to timestamps for matplotlib\n",
    "    idx = s.index.to_timestamp() if hasattr(s.index, \"to_timestamp\") else s.index\n",
    "    plt.plot(idx, s.values, label=label)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "# _plot_sharpe_series(rolling_markowitz, \"Markowitz-Sample Estimates\")\n",
    "_plot_sharpe_series(naive_returns, \"Naive 1/N\")\n",
    "# _plot_sharpe_series(lw_returns, \"Markowitz-Shrinkage Estimator\")\n",
    "# _plot_sharpe_series(cvx_returns, \"Constrained\")\n",
    "# _plot_sharpe_series(boot_returns, \"Resampled\")\n",
    "plt.legend()\n",
    "plt.title(\"Rolling Sharpe Ratios (36-month window)\")\n",
    "plt.xlabel(\"Time Period\")\n",
    "plt.ylabel(\"Sharpe Ratio\")\n",
    "plt.grid(True,linestyle='--',linewidth=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86af949e",
   "metadata": {},
   "source": [
    "## Cumulative Return Plot for All Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b5fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "def _plot_cum(series, label):\n",
    "\ts = (1 + series).cumprod()\n",
    "\tidx = s.index.to_timestamp() if hasattr(s.index, \"to_timestamp\") else s.index\n",
    "\tplt.plot(idx, s.values, label=label)\n",
    "\n",
    "# _plot_cum(rolling_markowitz, \"Rolling Markowitz\")\n",
    "_plot_cum(naive_returns, \"Naive 1/N\")\n",
    "# _plot_cum(lw_returns, \"Shirnkage\")\n",
    "# _plot_cum(cvx_returns, \"Constrained\")\n",
    "# _plot_cum(boot_returns, \"Resampling\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Cumulative Wealth\")\n",
    "plt.xlabel(\"Time Period\")\n",
    "plt.ylabel(\"Cummlative Retunrs\")\n",
    "plt.grid(visible=True,linestyle='--',linewidth='0.75')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40c6959",
   "metadata": {},
   "source": [
    "--------\n",
    "The above program is completely written by Hema Srikar Ankem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
